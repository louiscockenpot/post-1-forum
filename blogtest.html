<div style="font-family: Arial, Helvetica, sans-serif; color: #333; margin: 0; padding: 0; line-height: 1.6;">

    <div style="background-color: #555; color: white; padding: 10px 20px; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1);">
        <h1 style="margin: 0;">Proximal Policy Optimization</h1>
        <div style="margin: 10">
            <a href="#" style="color: white; text-decoration: none; padding: 5px 10px; font-size: 12px;">Christelle Le Van Khanh</a>
            <a href="#" style="color: white; text-decoration: none; padding: 5px 10px; font-size: 12px;">Anne Solene Izard</a>
            <a href="#" style="color: white; text-decoration: none; padding: 5px 10px; font-size: 12px;">Foucauld Estignard</a>
			<a href="#" style="color: white; text-decoration: none; padding: 5px 10px; font-size: 12px;">Louis Cockenpot</a>
			<a href="#" style="color: white; text-decoration: none; padding: 5px 10px; font-size: 12px;">Hector Mell Mariolle</a>			
        </div>
    </div>
	<div style="padding-left: 100px; padding-right: 100px">
		<div style="padding: 20px; background-color: transparent;">
			<h2>Introduction</h2>
			<p style="text-align: justify; margin-bottom: 30px;">Imagine a world where a computer program can master any game without even knowing its rules beforehand. A world where this program isn’t just playing games, but consistently outperforming the best human players, including world champions. This might sound like a plot from a sci-fi novel, but it's a reality made possible by an advanced field of artificial intelligence known as Reinforcement Learning (RL).</p>
			<img src="final.png" alt="AI mastering games" style="width: 50%; height: auto; display: block; margin: 0px auto;">
		</div>
		<div style="padding: 20;">
			<div style="display: flex; justify-content: center; align-items: flex-start; gap: 20px; margin-bottom: 20;">
				<div style="background-color: white; box-shadow: 0px 6px 12px rgba(0, 0, 0, 0.1) !important; padding: 20px; margin-bottom: 20px; border-radius: 5px !important; flex: 1 !important;">
					<h3>The Dawn of a New Era in AI </h3>
					<p style="margin: 5px 0; text-align: justify;">Reinforcement Learning has already made headlines with some major achievements. The historic win of AlphaGo, developed by DeepMind, over Lee Sedol, a world champion in the ancient game of Go, was a watershed moment. This victory wasn’t just about winning a game; it was a demonstration of the incredible potential of RL algorithms to tackle problems of immense complexity.</p>
					<p style="text-align: justify;">The prowess of RL doesn't stop there. AlphaStar, another brainchild of DeepMind, took the gaming world by storm by mastering the strategic depths of StarCraft 2, a game known for its intricate tactics and rapid decision-making. Similarly, OpenAI's robotic hand, adept at solving the Rubik’s Cube, shows the adaptability of RL in physical problem-solving tasks. These aren’t just triumphs in gaming; they're landmarks in the journey of AI.</p>
				</div>

				<div style="background-color: white; box-shadow: 0px 6px 12px rgba(0, 0, 0, 0.1) !important; padding: 20px; margin-bottom: 20px; border-radius: 5px !important; flex: 1 !important;">
					<h3>OpenAI and the Evolution of RL Techniques</h3>
					<p style="margin: 5px 0; text-align: justify;">The company we no longer need to introduce: OpenAI, made a significant contribution to the field of RL in 2017 by introducing Proximal Policy Optimization (PPO). This innovative technique quickly became a cornerstone algorithm at OpenAI, marking a new direction in the research and application of RL. PPO stands out for its efficiency and effectiveness in training AI models, particularly in complex environments where traditional RL methods struggle.</p>            					
					<p style="text-align: justify;">By optimizing policies in a more stable and reliable manner (we'll dive into that later) PPO has facilitated advancements in various AI applications, enhancing the capabilities and potential of artificial intelligence systems. This development by OpenAI represents a major milestone in RL, illustrating the organization's commitment to the field of AI.</p>
				</div>
			</div>
			<div style="display: flex; flex-wrap: wrap; gap: 20px; margin-bottom: 20px; align-items: center;">
				<div style="flex: 1; margin-right: 30px;">
					<img src="rlgif.gif" alt="Simple RL demo" style="width: 100%; height: auto;">
					<div style="color: grey; font-size: small; font-style: italic; text-align: center;">Source: kaggle.com/code/mohamedbakhet</div>
				</div>
				<div style="flex: 1; background-color: white; box-shadow: 0px 6px 12px rgba(0, 0, 0, 0.1); padding: 20px; border-radius: 5px;">
					<h3>Our Exploratory Path</h3>
					<p style="margin: 5px 0;">But to truly appreciate the significance of PPO and its impact, we need to start at the beginning. Our exploration will cover:</p>            
					<ul style="padding-left: 50px;">
						<li style="font-weight: bold;">Understanding Reinforcement Learning:</li>
							<p style="margin: 5px 0; padding-left: 20px; padding-right: 70px;">Delving into the basics of RL, we'll explore how this technology enables machines to learn from their interactions with the environment.</p>
						<li style="font-weight: bold;">The Role of Policy Gradient Methods:</li>
							<p style="margin: 5px 0; padding-left: 20px; padding-right: 70px;">Before we get to PPO, understanding policy gradient methods is crucial as they form the foundation upon which PPO is built.</p>
						<li style="font-weight: bold;">Demystifying Proximal Policy Optimization:</li>
							<p style="margin: 5px 0; padding-left: 20px; padding-right: 70px;">Finally, we'll dive deep into PPO, exploring its mechanics and why it's become a favored algorithm in RL.</p>
					</ul>
				</div>
			</div>
		</div>
	</div>

    <div style="background-color: #F1F1EF; text-align: center; padding: 10px 20px;">
        <h3>Stay Tuned for a Deep Dive into RL !</h3>
        <p>&copy; 2023 DIA1-G5 Forum</p>
    </div>

</div>
